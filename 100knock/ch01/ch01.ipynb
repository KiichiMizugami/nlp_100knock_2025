{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0863bdd1-7b0c-4f55-a984-ae9d9d4a2821",
   "metadata": {},
   "source": [
    "# 00. パタトクカシーー\n",
    "2つの文字列「パトカー」と「タクシー」の文字を先頭から交互に連結し、文字列「パタトクカシーー」を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a068b737-e6f4-4e78-9410-b07438e9fe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_01 = \"パトカー\"\n",
    "str_02 = \"タクシー\"\n",
    "\n",
    "generate_sentence = []\n",
    "for i in range(4):\n",
    "   generate_sentence.append(str_01[i] + str_02[i])\n",
    "\"\".join(generate_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f818bc-f8c7-48ac-99eb-cfd7223d41f3",
   "metadata": {},
   "source": [
    "# 01. タクシー\n",
    "文字列「パタトクカシーー」の2, 4, 6, 8文字目を取り出し、それらを連結した文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a78e5c-f9da-4f8c-b490-765dca6a4ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentence = \"パタトクカシーー\"\n",
    "\n",
    "taxi = []\n",
    "extract_number = [1,3,5,7]\n",
    "for i in range(len(generated_sentence)):\n",
    "    if i in extract_number:\n",
    "        taxi.append(generated_sentence[i])\n",
    "\"\".join(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9f729-cd80-4a8f-bc56-39e24beb675c",
   "metadata": {},
   "source": [
    "# 02. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef3c2a6-9742-4651-b933-2c8acb5775d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "reverse_sentence = \"stressed\"\n",
    "print(reverse_sentence[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cc980-f801-4f3f-aee7-66ea7483d348",
   "metadata": {},
   "source": [
    "# 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し、各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38935e4b-ea9c-4e0d-95a6-585c2539d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mizukamikiichi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_01 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "words = word_tokenize(sentence_01.replace(\",\",\"\").replace(\".\",\"\"))\n",
    "\n",
    "pi = []\n",
    "\n",
    "for i in range(len(words)):\n",
    "    pi.append(len(words[i]))\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039baa0c-2d27-41b1-bb57-095ec126a0b9",
   "metadata": {},
   "source": [
    "# 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し、1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字、それ以外の単語は先頭の2文字を取り出し、取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37464bfc-ac08-45bf-b4a9-b416ae37390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 11, 'Na': 12, 'Mi': 13, 'Al': 14, 'S': 15, 'P': 16, 'Se': 17, 'Cl': 18, 'Ar': 20, 'Ki': 21, 'Ca': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mizukamikiichi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sentence_02 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = word_tokenize(sentence_02)\n",
    "\n",
    "chemical_symbol = {}\n",
    "\n",
    "extract_numbers = [1,5,6,7,8,9,15,16,19]\n",
    "for i, word in enumerate(words, start = 1):\n",
    "    if word.isalpha():\n",
    "        if i in extract_numbers:\n",
    "            chemical_symbol[word[:1]] = i\n",
    "        else:\n",
    "            chemical_symbol[word[:2]] = i\n",
    "print(chemical_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b296db-0dbe-4d99-b857-b1baf0a918b8",
   "metadata": {},
   "source": [
    "# 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ。この関数を用い、”I am an NLPer”という文から文字tri-gram、単語bi-gramを得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbf7d0e-4c90-4222-a416-fd2fc5ad7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_maker(sentence,n):\n",
    " def splitter(sentence,n):\n",
    "     return [sentence[i:i+n] for i in range(len(sentence)-n+1)]\n",
    " char_gram = splitter(sentence,n)\n",
    "\n",
    " words = sentence.split()\n",
    " word_gram = splitter(words,n)\n",
    "\n",
    " print(\"文字 n-gram\", char_gram)\n",
    " print(\"単語 n-gram\", word_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364fbb89-7164-4d21-86cf-2413c7643bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字 n-gram ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "単語 n-gram [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "ngram_maker(\"I am an NLPer\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458955e8-16cc-40a2-9567-740b442927cd",
   "metadata": {},
   "source": [
    "# 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を、それぞれ, $X$と$Y$として求め,$X$と$Y$の和集合（$X \\cup Y$）、積集合（$X \\cap Y$）、差集合（$X \\setminus Y$）を求めよ。さらに、’se’というbi-gramがXおよびYに含まれるかどうかを調べよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0bc3a59-6f8d-4744-9dbb-d31f6235c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_splitter(sentence,n):\n",
    "    return {sentence[i:i+n] for i in range(len(sentence)-n+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fcc2ee4-3c8f-4fc6-a9fc-64a02c6e9a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gr', 'se', 'ap', 'is', 'pa', 'ag', 'ra', 'ph', 'ad', 'di', 'ar'}\n",
      "{'ap', 'ra', 'pa', 'ar'}\n",
      "{'di', 'is', 'ad', 'se'}\n",
      "'se' in X ? True\n",
      "'se' in Y ? False\n"
     ]
    }
   ],
   "source": [
    "X = word_splitter(\"paraparaparadise\",2)\n",
    "Y = word_splitter(\"paragraph\",2)\n",
    "\n",
    "cup = set(X) | set(Y)\n",
    "intersection = set(X) & set(Y)\n",
    "setminus = set(X) - set(Y)\n",
    "\n",
    "print(cup)\n",
    "print(intersection)\n",
    "print(setminus)\n",
    "print(\"'se' in X ?\",\"se\" in X)\n",
    "print(\"'se' in Y ?\",\"se\" in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72488ce-59ff-4a5d-8b79-aea806c393c5",
   "metadata": {},
   "source": [
    "# 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ。さらに、x=12, y=”気温”, z=22.4として、実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a61a1306-a507-491c-9992-22c227097e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(x,y,z):\n",
    "    print(f\"{x}時の{y}は{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59606c69-e2d9-43a3-92ca-6ada5212715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "weather(12,\"気温\",22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0cd82-b750-4a44-9318-d1b2b8bedad2",
   "metadata": {},
   "source": [
    "# 08. 暗号文\n",
    "与えられた文字列の各文字を、以下の仕様で変換する関数cipherを実装せよ。\n",
    "\n",
    "英小文字ならば (219 - 文字コード) のASCIIコードに対応する文字に置換\n",
    "\n",
    "その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い、英語のメッセージを暗号化・復号化せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5200394-f1c0-49d6-b2c9-4e08674aa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(data):\n",
    "\n",
    " Anngoubunn = []\n",
    "     \n",
    " for word in data:\n",
    "    if word.islower():\n",
    "          word_code = 219 - ord(word)\n",
    "          new_word = chr(word_code)\n",
    "          Anngoubunn.append(new_word)\n",
    "    else:\n",
    "          Anngoubunn.append(word)\n",
    " \n",
    " return \"\".join(Anngoubunn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6549ec8f-a2cb-40ed-8573-43f44390b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I zn zm NLPvi.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher(\"I am an NLPer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7e1517-3993-42b8-8b4a-cfe9e4b56d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an NLPer.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher('I zn zm NLPvi.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c8056-57b2-463c-97d9-ecc13b6691bb",
   "metadata": {},
   "source": [
    "# 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して、各単語の先頭と末尾の文字は残し、それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ。ただし、長さが４以下の単語は並び替えないこととする。適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え、その実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4d45a5d-6c70-41a6-8217-f428c3ba2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def typoglycemia(sentence):\n",
    "    generated_sentence = []\n",
    "    words = sentence.split()\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 4:\n",
    "            generated_sentence.append(word)\n",
    "        else:\n",
    "            initial = word[0]\n",
    "            last = word[-1]\n",
    "            middle = list(word[1:-1])\n",
    "\n",
    "            random.shuffle(middle)\n",
    "\n",
    "            shuffled_word = initial + \"\".join(middle) + last\n",
    "            generated_sentence.append(shuffled_word)\n",
    "            \n",
    "    return \" \".join(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1df70094-92fb-4122-8e1b-1341e5d44f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cudnol’t blveeie that I cuold aualclty uradsentnd what I was raindeg : the phnemnaoel pweor of the human mndi.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typoglycemia(\"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
